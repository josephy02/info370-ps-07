{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Hello y'all see this?\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "GYWdslI-sTsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhwSx51vSJgG"
      },
      "outputs": [],
      "source": [
        "# Connect Colab to Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip training data, run once\n",
        "#!unzip drive/MyDrive/data/train.zip -d drive/MyDrive/data/"
      ],
      "metadata": {
        "id": "mLLPHBB6WG6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip validation data, run once\n",
        "#!unzip drive/MyDrive/data/validation.zip -d drive/MyDrive/data/"
      ],
      "metadata": {
        "id": "UW1xlsZzaW1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code chunk puts absolute paths of all training/validation images and\n",
        "# their labels in seperate dataframes\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "validation_paths = []\n",
        "validation_labels = []\n",
        "troot = 'drive/MyDrive/data/train-cropped'\n",
        "vroot = 'drive/MyDrive/data/validation-cropped'\n",
        "\n",
        "for f in os.listdir(troot):\n",
        "  #tpath = os.path.join(troot, f)\n",
        "  tlabel = f[-10:-8]\n",
        "  train_paths.append(f)\n",
        "  train_labels.append(tlabel)\n",
        "\n",
        "for f in os.listdir(vroot):\n",
        "  #vpath = os.path.join(vroot, f)\n",
        "  vlabel = f[-10:-8]\n",
        "  validation_paths.append(f)\n",
        "  validation_labels.append(vlabel)\n",
        "\n",
        "train_images = pd.DataFrame({'path': train_paths,\n",
        "                             'label': train_labels})\n",
        "validation_images = pd.DataFrame({'path': validation_paths,\n",
        "                                  'label': validation_labels})"
      ],
      "metadata": {
        "id": "x-vpLAwseCZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subset(n, data, seed=123):\n",
        "  \"\"\"\n",
        "  input: number of samples, dataframe to be sampled from\n",
        "\n",
        "  output: subset of rows from dataframe\n",
        "  \"\"\"\n",
        "  random.seed(seed)\n",
        "  sub = random.sample(range(data.shape[0] + 1), n)\n",
        "  return data.iloc[sub,:]"
      ],
      "metadata": {
        "id": "H92_LMq-4xFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageWidth, imageHeight = 128, 128\n",
        "channel = 1\n",
        "imageSize = (imageWidth, imageHeight)\n",
        "nCategories = 5\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 64,\n",
        "                 kernel_size=2,\n",
        "                 activation='relu',\n",
        "                 input_shape=(imageWidth, imageHeight, channel)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(16,\n",
        "                 kernel_size = 2,\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Conv2D(filters = 128,\n",
        "#                 kernel_size=2,\n",
        "#                 activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nCategories, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WiWL0gtE2ED5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data generator\n",
        "\n",
        "train_subset = get_subset(1000, train_images)\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ").flow_from_dataframe(\n",
        "    dataframe = train_subset,\n",
        "    directory = troot,         # `train_subset` contains absolute paths\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',  # target is 2-D array of one-hot encoded labels\n",
        "    target_size=imageSize,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False\n",
        "    )\n",
        "label_map = train_generator.class_indices"
      ],
      "metadata": {
        "id": "NXYyrEJgzQ9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training:\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs = 1\n",
        ")"
      ],
      "metadata": {
        "id": "j7L8DF4i5WKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare validation data generator\n",
        "\n",
        "validation_subset = get_subset(1000, validation_images)\n",
        "\n",
        "validation_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ").flow_from_dataframe(\n",
        "    dataframe = validation_subset,\n",
        "    directory = vroot,\n",
        "    x_col='path',\n",
        "    class_mode= None,\n",
        "    target_size=imageSize,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False\n",
        "    )"
      ],
      "metadata": {
        "id": "EquZtlmn5WZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make categorical prediction:\n",
        "print(\" --- Predicting on validation data ---\")\n",
        "phat = model.predict(validation_generator)\n",
        "print(\"Predicted probability array shape:\", phat.shape)\n",
        "print(\"Example:\\n\", phat[:5])"
      ],
      "metadata": {
        "id": "70Vl0RQc6Y-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert labels to categories:\n",
        "validation_subset['predicted'] = pd.Series(np.argmax(phat, axis=1),\n",
        "                                           index=validation_subset.index)\n",
        "print(validation_subset.head())\n",
        "labelMap = {v: k for k, v in label_map.items()}\n",
        "validation_subset[\"predicted\"] = validation_subset.predicted.replace(labelMap)\n",
        "print(\"confusion matrix (validation)\")\n",
        "print(pd.crosstab(validation_subset.label, validation_subset.predicted))\n",
        "print(\"Validation accuracy\", np.mean(validation_subset.label == validation_subset.predicted))"
      ],
      "metadata": {
        "id": "LDBPaibc7UYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Print and plot misclassified results\n",
        "wrongResults = validation_subset[validation_subset.predicted != validation_subset.label]\n",
        "rows = np.random.choice(wrongResults.index, min(4, wrongResults.shape[0]), replace=False)\n",
        "print(\"Example wrong results (validation data)\")\n",
        "print(wrongResults.sample(min(10, wrongResults.shape[0])))\n",
        "\n",
        "## Plot 4 wrong and 4 correct results\n",
        "plt.figure(figsize=(12, 12))\n",
        "index = 1\n",
        "for row in rows:\n",
        "    filename = wrongResults.loc[row, 'path']\n",
        "    predicted = wrongResults.loc[row, 'predicted']\n",
        "    img = load_img(os.path.join(vpath, filename), target_size=imageSize)\n",
        "    plt.subplot(4, 2, index)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + \" ({})\".format(predicted))\n",
        "    index += 1\n",
        "# now show correct results\n",
        "index = 5\n",
        "correctResults = validation_subset[validation_subset.predicted == validation_subset.label]\n",
        "rows = np.random.choice(correctResults.index,\n",
        "                        min(4, correctResults.shape[0]), replace=False)\n",
        "for row in rows:\n",
        "    filename = correctResults.loc[row, 'path']\n",
        "    predicted = correctResults.loc[row, 'predicted']\n",
        "    img = load_img(os.path.join(vpath, filename), target_size=imageSize)\n",
        "    plt.subplot(4, 2, index)\n",
        "    plt.imshow(img)\n",
        "    plt.xlabel(filename + \" ({})\".format(predicted))\n",
        "    index += 1\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b_sDC-cVDwXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}