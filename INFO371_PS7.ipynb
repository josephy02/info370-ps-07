{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Hello y'all see this?\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "GYWdslI-sTsX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yhwSx51vSJgG",
        "outputId": "32d8ecdd-0ec3-47a7-e7bd-4ada6a3f3f04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect Colab to Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip training data, run once\n",
        "#!unzip drive/MyDrive/data/train.zip -d drive/MyDrive/data/"
      ],
      "metadata": {
        "id": "mLLPHBB6WG6O"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip validation data, run once\n",
        "#!unzip drive/MyDrive/data/validation.zip -d drive/MyDrive/data/"
      ],
      "metadata": {
        "id": "UW1xlsZzaW1b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code chunk puts absolute paths of all training/validation images and\n",
        "# their labels in seperate dataframes\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "validation_paths = []\n",
        "validation_labels = []\n",
        "troot = 'drive/MyDrive/data/train-cropped'\n",
        "vroot = 'drive/MyDrive/data/validation-cropped'\n",
        "\n",
        "for f in os.listdir(troot):\n",
        "  tpath = os.path.join(troot, f)\n",
        "  tlabel = f[-10:-8]\n",
        "  train_paths.append(tpath)\n",
        "  train_labels.append(tlabel)\n",
        "\n",
        "for f in os.listdir(vroot):\n",
        "  vpath = os.path.join(vroot, f)\n",
        "  vlabel = f[-10:-8]\n",
        "  validation_paths.append(vpath)\n",
        "  validation_labels.append(vlabel)\n",
        "\n",
        "train_images = pd.DataFrame({'path': train_paths,\n",
        "                             'label': train_labels})\n",
        "validation_images = pd.DataFrame({'path': validation_paths,\n",
        "                                  'label': validation_labels})"
      ],
      "metadata": {
        "id": "x-vpLAwseCZF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subset(n, data, seed=123):\n",
        "  \"\"\"\n",
        "  input: number of samples, dataframe to be sampled from\n",
        "\n",
        "  output: subset of rows from dataframe\n",
        "  \"\"\"\n",
        "  random.seed(seed)\n",
        "  sub = random.sample(range(data.shape[0] + 1), n)\n",
        "  return data.iloc[sub,:]"
      ],
      "metadata": {
        "id": "H92_LMq-4xFX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageWidth, imageHeight = 128, 128\n",
        "channel = 1\n",
        "imageSize = (imageWidth, imageHeight)\n",
        "nCategories = 5\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 64,\n",
        "                 kernel_size=2,\n",
        "                 activation='relu',\n",
        "                 input_shape=(imageWidth, imageHeight, channel)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(16,\n",
        "                 kernel_size = 2,\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Conv2D(filters = 128,\n",
        "#                 kernel_size=2,\n",
        "#                 activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "#model.add(MaxPooling2D(pool_size=2))\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nCategories, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WiWL0gtE2ED5",
        "outputId": "36ee4754-a6f6-4870-bb40-e3dcfcb8dda9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 127, 127, 64)      320       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 127, 127, 64)      256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 63, 63, 64)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 63, 63, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 62, 62, 16)        4112      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 62, 62, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 31, 31, 16)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 31, 31, 16)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 15376)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                492064    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 32)                128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 165       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 497109 (1.90 MB)\n",
            "Trainable params: 496885 (1.90 MB)\n",
            "Non-trainable params: 224 (896.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data generator\n",
        "\n",
        "train_subset = get_subset(1000, train_images)\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ").flow_from_dataframe(\n",
        "    dataframe = train_subset,\n",
        "    directory = None,         # `train_subset` contains absolute paths\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',  # target is 2-D array of one-hot encoded labels\n",
        "    target_size=imageSize,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False\n",
        "    )\n",
        "label_map = train_generator.class_indices"
      ],
      "metadata": {
        "id": "NXYyrEJgzQ9A",
        "outputId": "2ccc8b6d-1c86-4ba5-93e3-bdf43d73a4a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 validated image filenames belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training:\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs = 1\n",
        ")"
      ],
      "metadata": {
        "id": "j7L8DF4i5WKL",
        "outputId": "dd46360f-6761-4657-f538-cd4de84ff648",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/32 [================>.............] - ETA: 26s - loss: 0.9832 - accuracy: 0.6530"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare validation data generator\n",
        "\n",
        "validation_subset = get_subset(1000, validation_images)\n",
        "\n",
        "validation_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ").flow_from_dataframe(\n",
        "    dataframe = validation_subset,\n",
        "    directory = None,\n",
        "    x_col='path',\n",
        "    class_mode= None,\n",
        "    target_size=imageSize,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False\n",
        "    )"
      ],
      "metadata": {
        "id": "EquZtlmn5WZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make categorical prediction:\n",
        "print(\" --- Predicting on validation data ---\")\n",
        "phat = model.predict(validation_generator)\n",
        "print(\"Predicted probability array shape:\", phat.shape)\n",
        "print(\"Example:\\n\", phat[:5])"
      ],
      "metadata": {
        "id": "70Vl0RQc6Y-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert labels to categories:\n",
        "validation_subset['predicted'] = pd.Series(np.argmax(phat, axis=1),\n",
        "                                           index=validation_subset.index)\n",
        "print(validation_subset.head())\n",
        "labelMap = {v: k for k, v in label_map.items()}\n",
        "validation_subset[\"predicted\"] = validation_subset.predicted.replace(labelMap)\n",
        "print(\"confusion matrix (validation)\")\n",
        "print(pd.crosstab(validation_subset.label, validation_subset.predicted))\n",
        "print(\"Validation accuracy\", np.mean(validation_subset.label == validation_subset.predicted))"
      ],
      "metadata": {
        "id": "LDBPaibc7UYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}