{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Hello y'all see this?\n",
        "\"\"\"\n",
        "from google.colab import drive\n",
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "GYWdslI-sTsX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "yhwSx51vSJgG",
        "outputId": "e0de42c0-9a26-4b41-cfaa-eceefc495344",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connect Colab to Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip training data, run once\n",
        "#!unzip drive/MyDrive/data/train.zip -d drive/MyDrive/data/"
      ],
      "metadata": {
        "id": "mLLPHBB6WG6O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip validation data, run once\n",
        "#!unzip drive/MyDrive/data/validation.zip -d drive/MyDrive/data/"
      ],
      "metadata": {
        "id": "UW1xlsZzaW1b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code chunk puts absolute paths of all training/validation images and\n",
        "# their labels in seperate dataframes\n",
        "train_paths = []\n",
        "train_labels = []\n",
        "validation_paths = []\n",
        "validation_labels = []\n",
        "troot = 'drive/MyDrive/data/train-cropped'\n",
        "vroot = 'drive/MyDrive/data/validation-cropped'\n",
        "\n",
        "for f in os.listdir(troot):\n",
        "  tpath = os.path.join(troot, f)\n",
        "  tlabel = f[-10:-8]\n",
        "  train_paths.append(tpath)\n",
        "  train_labels.append(tlabel)\n",
        "\n",
        "for f in os.listdir(vroot):\n",
        "  vpath = os.path.join(vroot, f)\n",
        "  vlabel = f[-10:-8]\n",
        "  validation_paths.append(vpath)\n",
        "  validation_labels.append(vlabel)\n",
        "\n",
        "train_images = pd.DataFrame({'path': train_paths,\n",
        "                             'label': train_labels})\n",
        "validation_images = pd.DataFrame({'path': validation_paths,\n",
        "                                  'label': validation_labels})"
      ],
      "metadata": {
        "id": "x-vpLAwseCZF",
        "outputId": "be351549-f042-46ae-8115-e4a8d94900b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "[Errno 5] Input/output error: 'drive/MyDrive/data/train-cropped'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-31b4d5b69afe>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mvroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'drive/MyDrive/data/validation-cropped'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mtpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mtlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: 'drive/MyDrive/data/train-cropped'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subset(n, data, seed=123):\n",
        "  \"\"\"\n",
        "  input: number of samples, dataframe to be sampled from\n",
        "\n",
        "  output: subset of rows from dataframe\n",
        "  \"\"\"\n",
        "  random.seed(seed)\n",
        "  sub = random.sample(range(data.shape[0] + 1), n)\n",
        "  return data.iloc[sub,:]"
      ],
      "metadata": {
        "id": "H92_LMq-4xFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imageWidth, imageHeight = 128, 128\n",
        "channel = 1\n",
        "imageSize = (imageWidth, imageHeight)\n",
        "nCategories = 5\n",
        "\n",
        "# Create model\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 32,\n",
        "                 kernel_size=2,\n",
        "                 activation='relu',\n",
        "                 input_shape=(imageWidth, imageHeight, channel)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,\n",
        "                 kernel_size = 2,\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 128,\n",
        "                 kernel_size=2,\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(nCategories, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "WiWL0gtE2ED5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare training data generator\n",
        "\n",
        "train_subset = get_subset(1000, train_images)\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ").flow_from_dataframe(\n",
        "    dataframe = train_subset,\n",
        "    directory = None,         # `train_subset` contains absolute paths\n",
        "    x_col='path',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',  # target is 2-D array of one-hot encoded labels\n",
        "    target_size=imageSize,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False\n",
        "    )\n",
        "label_map = train_generator.class_indices"
      ],
      "metadata": {
        "id": "NXYyrEJgzQ9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model Training:\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs = 1\n",
        ")"
      ],
      "metadata": {
        "id": "j7L8DF4i5WKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare validation data generator\n",
        "\n",
        "validation_subset = get_subset(1000, validation_images)\n",
        "\n",
        "validation_generator = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        ").flow_from_dataframe(\n",
        "    dataframe = validation_subset,\n",
        "    directory = None,\n",
        "    x_col='path',\n",
        "    class_mode= None,\n",
        "    target_size=imageSize,\n",
        "    color_mode=\"grayscale\",\n",
        "    shuffle=False\n",
        "    )"
      ],
      "metadata": {
        "id": "EquZtlmn5WZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Make categorical prediction:\n",
        "print(\" --- Predicting on validation data ---\")\n",
        "phat = model.predict(validation_generator)\n",
        "print(\"Predicted probability array shape:\", phat.shape)\n",
        "print(\"Example:\\n\", phat[:5])"
      ],
      "metadata": {
        "id": "70Vl0RQc6Y-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Convert labels to categories:\n",
        "validation_subset['predicted'] = pd.Series(np.argmax(phat, axis=1),\n",
        "                                           index=validation_subset.index)\n",
        "print(validation_subset.head())\n",
        "labelMap = {v: k for k, v in label_map.items()}\n",
        "validation_subset[\"predicted\"] = validation_subset.predicted.replace(labelMap)\n",
        "print(\"confusion matrix (validation)\")\n",
        "print(pd.crosstab(validation_subset.category, validation_subset.predicted))\n",
        "print(\"Validation accuracy\", np.mean(validation_subset.category == validation_subset.predicted))"
      ],
      "metadata": {
        "id": "LDBPaibc7UYp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}